{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import helper\n",
    "import pandas as pd\n",
    "import csv \n",
    "from nltk.cluster import KMeansClusterer\n",
    "import nltk\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Handle input\n",
    "\n",
    "# trainingdata = pd.read_csv(\"../datasets/train/SemEval2018-T3-train-taskA_emoji.txt\", delimiter = \"\\t\",  quoting=csv.QUOTE_NONE, header=0)\n",
    "# tweets = trainingdata['Tweet text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an empty list\n",
    "tweets = []\n",
    "\n",
    "# open file and read the content in a list\n",
    "with open('tweets_corpus.txt', 'r') as filehandle:  \n",
    "    for line in filehandle:\n",
    "        # remove linebreak which is the last character of the string\n",
    "        currentPlace = line[:-1]\n",
    "\n",
    "        # add item to the list\n",
    "        tweets.append(currentPlace)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = helper.allbags(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Word2Vec maker\n",
    "\n",
    "model = Word2Vec(corpus, min_count=5, size=200, window=8)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.wv.index2word\n",
    "X = model.wv[words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('realise', 0.9363247156143188),\n",
       " ('offend', 0.9210367202758789),\n",
       " ('dumb', 0.9173310399055481),\n",
       " ('pose', 0.9084862470626831),\n",
       " ('fucking', 0.9083322286605835),\n",
       " ('soo', 0.9072073698043823),\n",
       " ('dislike', 0.9044171571731567),\n",
       " ('subtweet', 0.9040661454200745),\n",
       " ('hashtags', 0.9028514623641968),\n",
       " ('rant', 0.8909350633621216)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['stupid'], negative=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gebruik sklearn want multithread\n",
    "\n",
    "kmeans = cluster.KMeans(n_clusters=2000, precompute_distances=True)\n",
    "kmeans.fit(X)\n",
    " \n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    " \n",
    "print (\"Cluster id labels for inputted data\")\n",
    "print (labels)\n",
    "print (\"Centroids data\")\n",
    "print (centroids)\n",
    " \n",
    "print (\"Score (Opposite of the value of X on the K-means objective which is Sum of distances of samples to their closest cluster center):\")\n",
    "print (kmeans.score(X))\n",
    " \n",
    "silhouette_score = metrics.silhouette_score(X, labels, metric='euclidean')\n",
    " \n",
    "print (\"Silhouette_score: \")\n",
    "print (silhouette_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.predict([model.wv['dog'],model['haha']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n",
      "/root/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[1845, 57, 432, 78, 944]], [[63, 126, 232, 1498]]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputbag = helper.allbags([\"Hi my name is jeff\", \"I think you're cool\"])\n",
    "resulting_clusters = []\n",
    "\n",
    "for row in inputbag:\n",
    "    clusters_row = []\n",
    "    filtered_words = list(filter(lambda x: x in words, row))\n",
    "    clusters_row.append(list(kmeans.predict(model[filtered_words])))\n",
    "    resulting_clusters.append(clusters_row)\n",
    "            \n",
    "resulting_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'think', \"you're\", 'cool']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "## Save the classifier\n",
    "_ = joblib.dump(kmeans, \"kmeansclass.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/root/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[152, 1702, 1658, 1658, 1350], [1719, 1658, 1719, 1296]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load the classifier\n",
    "kmeansmodel = joblib.load(\"kmeansclass.model\")\n",
    "w2vmodel = Word2Vec.load(\"word2vec.model\")\n",
    "vocab = w2vmodel.wv.index2word\n",
    "\n",
    "inputbag = helper.allbags([\"Hi my name is jeff\", \"I think you're cool\"])\n",
    "resulting_clusters = []\n",
    "\n",
    "for row in inputbag:\n",
    "    filtered_words = list(filter(lambda x: x in vocab, row))\n",
    "    resulting_clusters.append(list(kmeansmodel.predict(model[filtered_words])))\n",
    "            \n",
    "resulting_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "onehotvec = np.zeros((len(resulting_clusters), 2000))\n",
    "for i in range(len(resulting_clusters)):\n",
    "    onehotvec[i, resulting_clusters[i]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 1, 1, 1]),\n",
       " array([ 152, 1350, 1658, 1702, 1296, 1658, 1719]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(onehotvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
