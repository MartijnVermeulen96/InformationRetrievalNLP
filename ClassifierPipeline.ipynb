{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import twokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from FeatureFunctions import getfeatures\n",
    "from FeatureFunctions import helper\n",
    "from sklearn.externals import joblib\n",
    "from gensim.models import Word2Vec\n",
    "from importlib import reload\n",
    "\n",
    "import sklearn\n",
    "import csv\n",
    "\n",
    "\n",
    "### Import the classifier\n",
    "import sys\n",
    "sys.path.insert(0, 'libsvm')\n",
    "\n",
    "from svmutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whichtask = input(\"Which task to you want to do (A/B): \")\n",
    "whichtask = \"A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading train and test files\n",
    "\n",
    "datafile = \"datasets/train/SemEval2018-T3-train-task\"+whichtask+\"_emoji.txt\"\n",
    "# datafile = \"datasets/train/SemEval2018-T3-train-task\"+whichtask+\"_emoji_ironyHashtags.txt\"\n",
    "\n",
    "trainingdata = pd.read_csv(datafile, delimiter = \"\\t\",  quoting=csv.QUOTE_NONE, header=0)\n",
    "trainingdata = trainingdata[['Label','Tweet text']]\n",
    "\n",
    "testfile = 'datasets/goldtest_Task'+whichtask+'/SemEval2018-T3_gold_test_task'+whichtask+'_emoji.txt'\n",
    "testdata = pd.read_csv(testfile, sep=\"\\t\",  quoting=csv.QUOTE_NONE, header=0)\n",
    "testdata = testdata[['Label','Tweet text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'FeatureFunctions.helper' from '/root/Documents/TU_Delft/InformationRetrieval/NLP/InformationRetrievalNLP/FeatureFunctions/helper.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_posfeatures = helper.getPOSfeatures(\"FeatureFunctions/POStrain.txt\")\n",
    "test_posfeatures = helper.getPOSfeatures(\"FeatureFunctions/POStest.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get lexical features\n",
    "# training_features\n",
    "lexical_training_features, unicount_vect, bicount_vect, tricount_vect, fourcount_vect = getfeatures.getlexical(trainingdata, 'Tweet text')\n",
    "x_small = lexical_training_features[['PunctuationFlood', 'CharFlood', 'CapitalizedCount', 'HashtagCount', 'Hashtag2WordRatio', 'TweetCharLength', 'TweetWordLength', 'EmojiCount', 'FinalPunctuation']].values\n",
    "x_lexical = np.array(lexical_training_features.apply(lambda row: sum([row['CharFourgramVector'], row['CharTrigramVector'],row['BigramVector']], []), axis=1).values.tolist())\n",
    "x_lexical = np.hstack((x_small, x_lexical))\n",
    "\n",
    "# train_bow = lexical_training_features['UnigramVector'].values.tolist()\n",
    "\n",
    "# test_features\n",
    "lexical_test_features, unicount_vect, bicount_vect, tricount_vect, fourcount_vect = getfeatures.getlexical(testdata, 'Tweet text', unicount_vect, bicount_vect, tricount_vect, fourcount_vect)\n",
    "test_x_small = lexical_test_features[['PunctuationFlood', 'CharFlood', 'CapitalizedCount', 'HashtagCount', 'Hashtag2WordRatio', 'TweetCharLength', 'TweetWordLength', 'EmojiCount', 'FinalPunctuation']].values\n",
    "test_lexical_x = np.array(lexical_test_features.apply(lambda row: sum([row['CharFourgramVector'], row['CharTrigramVector'],row['BigramVector']], []), axis=1).values.tolist())\n",
    "test_lexical_x = np.hstack((test_x_small, test_lexical_x))\n",
    "\n",
    "train_bow = np.array(lexical_training_features['UnigramVector'].values.tolist())\n",
    "test_bow = np.array(lexical_test_features['UnigramVector'].values.tolist())\n",
    "\n",
    "lexical_training_features = []\n",
    "lexical_test_features = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the classifier\n",
    "kmeansmodel = joblib.load(\"FeatureFunctions/kmeansclass.model\")\n",
    "w2vmodel = Word2Vec.load(\"FeatureFunctions/word2vec.model\")\n",
    "\n",
    "train_bags = helper.allbags(trainingdata['Tweet text'])\n",
    "word2vecfeatures_train = helper.onehotwordclusters(train_bags, kmeansmodel, w2vmodel).astype(int)\n",
    "\n",
    "test_bags = helper.allbags(testdata['Tweet text'])\n",
    "word2vecfeatures_test = helper.onehotwordclusters(test_bags, kmeansmodel, w2vmodel).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(getfeatures)\n",
    "\n",
    "### Get sentiment features\n",
    "train_sentiment_x = getfeatures.getaffinfeats(trainingdata['Tweet text'])\n",
    "test_sentiment_x = getfeatures.getaffinfeats(testdata['Tweet text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many iterations: 10\n",
      "Do you want to use a heldout set (1=heldout, 0=crossvalidate): 0\n",
      "Which type to test: 6\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 96217)\n",
      "\n",
      "Accuracy = 96.501% (2951/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 96217)\n",
      "\n",
      "Accuracy = 90.0262% (686/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9472    0.8478    0.8947       381\n",
      "           1     0.8622    0.9528    0.9052       381\n",
      "\n",
      "   micro avg     0.9003    0.9003    0.9003       762\n",
      "   macro avg     0.9047    0.9003    0.9000       762\n",
      "weighted avg     0.9047    0.9003    0.9000       762\n",
      "\n",
      "Precision: 0.8622327790973872\n",
      "Recall: 0.952755905511811\n",
      "F1-score: 0.9052369077306732\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          323   58  381\n",
      "1           18  363  381\n",
      "All        341  421  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 2/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 96217)\n",
      "\n",
      "Accuracy = 96.3048% (2945/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 96217)\n",
      "\n",
      "Accuracy = 90.1575% (687/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9250    0.8740    0.8988       381\n",
      "           1     0.8806    0.9291    0.9042       381\n",
      "\n",
      "   micro avg     0.9016    0.9016    0.9016       762\n",
      "   macro avg     0.9028    0.9016    0.9015       762\n",
      "weighted avg     0.9028    0.9016    0.9015       762\n",
      "\n",
      "Precision: 0.8805970149253731\n",
      "Recall: 0.9291338582677166\n",
      "F1-score: 0.9042145593869733\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          333   48  381\n",
      "1           27  354  381\n",
      "All        360  402  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 3/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 96217)\n",
      "\n",
      "Accuracy = 96.501% (2951/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 96217)\n",
      "\n",
      "Accuracy = 89.3701% (681/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9310    0.8504    0.8889       381\n",
      "           1     0.8623    0.9370    0.8981       381\n",
      "\n",
      "   micro avg     0.8937    0.8937    0.8937       762\n",
      "   macro avg     0.8967    0.8937    0.8935       762\n",
      "weighted avg     0.8967    0.8937    0.8935       762\n",
      "\n",
      "Precision: 0.8623188405797102\n",
      "Recall: 0.937007874015748\n",
      "F1-score: 0.8981132075471698\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          324   57  381\n",
      "1           24  357  381\n",
      "All        348  414  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 4/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 96217)\n",
      "\n",
      "Accuracy = 96.6318% (2955/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 96217)\n",
      "\n",
      "Accuracy = 89.1076% (679/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9382    0.8373    0.8849       381\n",
      "           1     0.8531    0.9449    0.8966       381\n",
      "\n",
      "   micro avg     0.8911    0.8911    0.8911       762\n",
      "   macro avg     0.8957    0.8911    0.8908       762\n",
      "weighted avg     0.8957    0.8911    0.8908       762\n",
      "\n",
      "Precision: 0.8530805687203792\n",
      "Recall: 0.9448818897637795\n",
      "F1-score: 0.896637608966376\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          319   62  381\n",
      "1           21  360  381\n",
      "All        340  422  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 5/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 96217)\n",
      "\n",
      "Accuracy = 96.4356% (2949/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 96217)\n",
      "\n",
      "Accuracy = 90.5512% (690/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9377    0.8688    0.9019       381\n",
      "           1     0.8778    0.9423    0.9089       381\n",
      "\n",
      "   micro avg     0.9055    0.9055    0.9055       762\n",
      "   macro avg     0.9077    0.9055    0.9054       762\n",
      "weighted avg     0.9077    0.9055    0.9054       762\n",
      "\n",
      "Precision: 0.8777506112469438\n",
      "Recall: 0.9422572178477691\n",
      "F1-score: 0.908860759493671\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          331   50  381\n",
      "1           22  359  381\n",
      "All        353  409  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 6/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 96217)\n",
      "\n",
      "Accuracy = 96.6972% (2957/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 96217)\n",
      "\n",
      "Accuracy = 89.6325% (683/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9314    0.8556    0.8919       381\n",
      "           1     0.8665    0.9370    0.9004       381\n",
      "\n",
      "   micro avg     0.8963    0.8963    0.8963       762\n",
      "   macro avg     0.8990    0.8963    0.8962       762\n",
      "weighted avg     0.8990    0.8963    0.8962       762\n",
      "\n",
      "Precision: 0.866504854368932\n",
      "Recall: 0.937007874015748\n",
      "F1-score: 0.9003783102143758\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          326   55  381\n",
      "1           24  357  381\n",
      "All        350  412  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 7/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 96217)\n",
      "\n",
      "Accuracy = 96.7299% (2958/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 96217)\n",
      "\n",
      "Accuracy = 88.9764% (678/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9433    0.8294    0.8827       381\n",
      "           1     0.8478    0.9501    0.8960       381\n",
      "\n",
      "   micro avg     0.8898    0.8898    0.8898       762\n",
      "   macro avg     0.8955    0.8898    0.8894       762\n",
      "weighted avg     0.8955    0.8898    0.8894       762\n",
      "\n",
      "Precision: 0.8477751756440282\n",
      "Recall: 0.9501312335958005\n",
      "F1-score: 0.8960396039603962\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          316   65  381\n",
      "1           19  362  381\n",
      "All        335  427  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 8/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 96217)\n",
      "\n",
      "Accuracy = 96.7299% (2958/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 96217)\n",
      "\n",
      "Accuracy = 89.2388% (680/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9436    0.8346    0.8858       381\n",
      "           1     0.8518    0.9501    0.8983       381\n",
      "\n",
      "   micro avg     0.8924    0.8924    0.8924       762\n",
      "   macro avg     0.8977    0.8924    0.8920       762\n",
      "weighted avg     0.8977    0.8924    0.8920       762\n",
      "\n",
      "Precision: 0.851764705882353\n",
      "Recall: 0.9501312335958005\n",
      "F1-score: 0.8982630272952854\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          318   63  381\n",
      "1           19  362  381\n",
      "All        337  425  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 9/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 96217)\n",
      "\n",
      "Accuracy = 96.6645% (2956/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 96217)\n",
      "\n",
      "Accuracy = 90.1575% (687/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9500    0.8478    0.8960       381\n",
      "           1     0.8626    0.9554    0.9066       381\n",
      "\n",
      "   micro avg     0.9016    0.9016    0.9016       762\n",
      "   macro avg     0.9063    0.9016    0.9013       762\n",
      "weighted avg     0.9063    0.9016    0.9013       762\n",
      "\n",
      "Precision: 0.8625592417061612\n",
      "Recall: 0.9553805774278216\n",
      "F1-score: 0.9066002490660025\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          323   58  381\n",
      "1           17  364  381\n",
      "All        340  422  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 10/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 96217)\n",
      "\n",
      "Accuracy = 96.5991% (2954/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 96217)\n",
      "\n",
      "Accuracy = 90.2887% (688/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9398    0.8609    0.8986       381\n",
      "           1     0.8717    0.9449    0.9068       381\n",
      "\n",
      "   micro avg     0.9029    0.9029    0.9029       762\n",
      "   macro avg     0.9057    0.9029    0.9027       762\n",
      "weighted avg     0.9057    0.9029    0.9027       762\n",
      "\n",
      "Precision: 0.8716707021791767\n",
      "Recall: 0.9448818897637795\n",
      "F1-score: 0.9068010075566751\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          328   53  381\n",
      "1           21  360  381\n",
      "All        349  413  762\n",
      "Combined results with 10 iterations: \n",
      "89.75 ±1.05 -88.98 +90.55\t86.36 ±2.07 -84.78 +88.06\t94.44 ±1.55 -92.91 +95.54\t90.21 ±0.90 -89.60 +90.89\t\n"
     ]
    }
   ],
   "source": [
    "### Combining features\n",
    "iterations = int(input(\"How many iterations: \"))\n",
    "# nuSVC = int(input(\"Use nusvc? (1):\"))\n",
    "nuSVC = 0\n",
    "heldoutset = int(input(\"Do you want to use a heldout set (1=heldout, 0=crossvalidate): \"))\n",
    "whichtype = int(input(\"Which type to test: \"))\n",
    "results = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    print()\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(\"Iteration \" + str(i+1) + \"/\" + str(iterations))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print()\n",
    "    \n",
    "    ### Selecting the actual training samples (Do some crossover here )\n",
    "    if heldoutset:\n",
    "        trainingdata_result = trainingdata\n",
    "        testdata_result = testdata\n",
    "        resulting_train_index = range(len(trainingdata))\n",
    "        resulting_test_index = range(len(testdata_result))\n",
    "    else:\n",
    "        ## Crossvalidating\n",
    "        resulting_train_index, resulting_test_index = helper.getindices(trainingdata, 4, 1) # Get 80-20\n",
    "        trainingdata_result = trainingdata.loc[resulting_train_index]\n",
    "        testdata_result = trainingdata.loc[resulting_test_index]\n",
    "    \n",
    "    final_train_x = []\n",
    "    final_test_x = []\n",
    "\n",
    "    if heldoutset:\n",
    "        ## BoW\n",
    "        if whichtype == 1:\n",
    "            final_train_x = train_bow[resulting_train_index]\n",
    "            final_test_x = test_bow[resulting_test_index]\n",
    "        ## Lexical\n",
    "        if whichtype == 2:\n",
    "            final_train_x = np.hstack((train_bow[resulting_train_index], x_lexical[resulting_train_index]))\n",
    "            final_test_x = np.hstack((test_bow[resulting_test_index], test_lexical_x[resulting_test_index]))\n",
    "        ## Syntactic\n",
    "        if whichtype == 3:\n",
    "            final_train_x = train_posfeatures[resulting_train_index]\n",
    "            final_test_x = test_posfeatures[resulting_test_index]\n",
    "        ## Sentiment\n",
    "        if whichtype == 4:\n",
    "            final_train_x = train_sentiment_x[resulting_train_index]\n",
    "            final_test_x = test_sentiment_x[resulting_test_index]\n",
    "        ## Word2Vec\n",
    "        if whichtype == 5:\n",
    "            final_train_x = word2vecfeatures_train[resulting_train_index]\n",
    "            final_test_x = word2vecfeatures_test[resulting_test_index]\n",
    "        ## Combined\n",
    "        if whichtype == 6:\n",
    "            final_train_x = np.hstack((train_posfeatures[resulting_train_index], word2vecfeatures_train[resulting_train_index],train_bow[resulting_train_index], train_sentiment_x[resulting_train_index], x_lexical[resulting_train_index]))\n",
    "            final_test_x = np.hstack((test_posfeatures[resulting_test_index], word2vecfeatures_test[resulting_test_index], test_bow[resulting_test_index], test_sentiment_x[resulting_test_index], test_lexical_x[resulting_test_index]))\n",
    "    else:\n",
    "        ## Crossvalidating\n",
    "        ## BoW\n",
    "        if whichtype == 1:\n",
    "            final_train_x = train_bow[resulting_train_index]\n",
    "            final_test_x = train_bow[resulting_test_index]\n",
    "        ## Lexical\n",
    "        if whichtype == 2:\n",
    "            final_train_x = np.hstack((train_bow[resulting_train_index], x_lexical[resulting_train_index]))\n",
    "            final_test_x = np.hstack((train_bow[resulting_test_index], x_lexical[resulting_test_index]))\n",
    "        ## Syntactic\n",
    "        if whichtype == 3:\n",
    "            final_train_x = train_posfeatures[resulting_train_index]\n",
    "            final_test_x = train_posfeatures[resulting_test_index]\n",
    "        ## Sentiment\n",
    "        if whichtype == 4:\n",
    "            final_train_x = train_sentiment_x[resulting_train_index]\n",
    "            final_test_x = train_sentiment_x[resulting_test_index]\n",
    "        ## Word2Vec\n",
    "        if whichtype == 5:\n",
    "            final_train_x = word2vecfeatures_train[resulting_train_index]\n",
    "            final_test_x = word2vecfeatures_train[resulting_test_index]\n",
    "        ## Combined\n",
    "        if whichtype == 6:\n",
    "            final_train_x = np.hstack((train_posfeatures[resulting_train_index], word2vecfeatures_train[resulting_train_index], train_bow[resulting_train_index], train_sentiment_x[resulting_train_index], x_lexical[resulting_train_index]))\n",
    "            final_test_x = np.hstack((train_posfeatures[resulting_test_index], word2vecfeatures_train[resulting_test_index], train_bow[resulting_test_index], train_sentiment_x[resulting_test_index], x_lexical[resulting_test_index]))\n",
    "\n",
    "\n",
    "    print(\"###########\")\n",
    "    print(\"Training:\")\n",
    "    print(final_train_x.shape)\n",
    "    print()\n",
    "    ### Train and get train error\n",
    "    y = trainingdata_result['Label'].tolist()\n",
    "    prob  = svm_problem(y, final_train_x)\n",
    "    if nuSVC:\n",
    "        param = svm_parameter('-t 2 -s 1')\n",
    "    else:\n",
    "        param = svm_parameter('-t 2 -c 8 -g ' + str(2**-11))\n",
    "    m = svm_train(prob, param)\n",
    "    p_label, p_acc, p_val = svm_predict(y, final_train_x, m)\n",
    "    ACC, MSE, SCC = evaluations(y, p_label)\n",
    "\n",
    "    print()\n",
    "    print(\"###########\")\n",
    "    print(\"Testing:\")\n",
    "    print(final_test_x.shape)\n",
    "    print()\n",
    "\n",
    "\n",
    "    ### Get the test\n",
    "    test_y = testdata_result['Label'].tolist()\n",
    "\n",
    "    test_p_label, test_p_acc, test_p_val = svm_predict(test_y, final_test_x, m)\n",
    "    test_ACC, test_MSE, test_SCC = evaluations(test_y, test_p_label)\n",
    "    print(sklearn.metrics.classification_report(test_y, test_p_label, digits=4))\n",
    "\n",
    "    if whichtask == \"A\":\n",
    "        p, r, f = helper.precision_recall_fscore(test_y, test_p_label, beta=1, labels=[0,1], pos_label=1)\n",
    "    elif whichtask == \"B\":\n",
    "        p, r, f = helper.precision_recall_fscore(test_y, test_p_label, beta=1, labels=[0,1,2,3])\n",
    "\n",
    "    print(\"Precision: \" + str(p))\n",
    "    print(\"Recall: \" + str(r))\n",
    "    print(\"F1-score: \" + str(f))\n",
    "    \n",
    "    results.append([test_ACC, p*100, r*100, f*100])\n",
    "\n",
    "    y_actu = pd.Series(test_y, name='Actual')\n",
    "    y_pred = pd.Series(test_p_label, name='Predicted')\n",
    "    df_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print(df_confusion)\n",
    "    \n",
    "\n",
    "### Write output\n",
    "mean_results = np.mean(np.array(results), axis=0)\n",
    "std_results = 2*np.std(np.array(results), axis=0)\n",
    "min_results = np.min(np.array(results), axis=0)\n",
    "max_results = np.max(np.array(results), axis=0)\n",
    "\n",
    "if whichtype == 1:\n",
    "    sys.stdout.write(\"BoW results\")\n",
    "elif whichtype == 2:\n",
    "    sys.stdout.write(\"Lexical results\")\n",
    "elif whichtype == 3:\n",
    "    sys.stdout.write(\"Syntactical results\")\n",
    "elif whichtype == 4:\n",
    "    sys.stdout.write(\"Semantic results\")\n",
    "elif whichtype == 5:\n",
    "    sys.stdout.write(\"Word2Vec results\")\n",
    "elif whichtype == 6:\n",
    "    sys.stdout.write(\"Combined results\")\n",
    "    \n",
    "### stdout\n",
    "print(\" with \" + str(iterations) + \" iterations: \")\n",
    "for result_i in range(len(mean_results)):\n",
    "    sys.stdout.write(\"{:.2f}\".format(mean_results[result_i]))\n",
    "    sys.stdout.write(\" ±\" + \"{:.2f}\".format(std_results[result_i]))\n",
    "    sys.stdout.write(\" -\" + \"{:.2f}\".format(min_results[result_i]))\n",
    "    sys.stdout.write(\" +\" + \"{:.2f}\".format(max_results[result_i]) + \"\\t\")\n",
    "    \n",
    "    \n",
    "### file out\n",
    "with open(\"Results/resultswrite.txt\", \"a\") as outfile:\n",
    "    if whichtype == 1:\n",
    "        outfile.write(\"BoW results\")\n",
    "    elif whichtype == 2:\n",
    "        outfile.write(\"Lexical results\")\n",
    "    elif whichtype == 3:\n",
    "        outfile.write(\"Syntactical results\")\n",
    "    elif whichtype == 4:\n",
    "        outfile.write(\"Semantic results\")\n",
    "    elif whichtype == 5:\n",
    "        outfile.write(\"Word2Vec results\")\n",
    "    elif whichtype == 6:\n",
    "        outfile.write(\"Combined results\")\n",
    "\n",
    "    ### stdout\n",
    "    outfile.write(\" with \" + str(iterations) + \" iterations: \\n\")\n",
    "    for result_i in range(len(mean_results)):\n",
    "        outfile.write(\"{:.2f}\".format(mean_results[result_i]))\n",
    "        outfile.write(\" ±\" + \"{:.2f}\".format(std_results[result_i]))\n",
    "        outfile.write(\" -\" + \"{:.2f}\".format(min_results[result_i]))\n",
    "        outfile.write(\" +\" + \"{:.2f}\".format(max_results[result_i]) + \"\\t\")\n",
    "        \n",
    "    outfile.write(\"\\n\\n\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0 Not ironic\n",
      "473/473\n",
      "100.00%\n",
      "\n",
      "--- 1 Ironic by clash\n",
      "0/164\n",
      "0.00%\n",
      "\n",
      "--- 2 Situational irony\n",
      "0/85\n",
      "0.00%\n",
      "\n",
      "--- 3 Other irony\n",
      "0/62\n",
      "0.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if heldoutset:\n",
    "    ### Evaluate results per category (Sectie 5.2)\n",
    "\n",
    "    testfileB = 'datasets/goldtest_TaskB/SemEval2018-T3_gold_test_taskB_emoji.txt'\n",
    "    testdataB = pd.read_csv(testfileB, sep=\"\\t\",  quoting=csv.QUOTE_NONE, header=0)\n",
    "    testdataB = testdataB[['Label','Tweet text']]\n",
    "\n",
    "    ## Getting category information\n",
    "    used_testB = testdataB.loc[resulting_test_index]\n",
    "    used_testB.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    ## Nonirony\n",
    "    print(\"--- 0 Not ironic\")\n",
    "    predB_nonirony = sum((used_testB['Label'] == 0) & (y_pred == 0))\n",
    "    testB_nonirony = sum((used_testB['Label'] == 0))\n",
    "    print(str(predB_nonirony) + \"/\" + str(testB_nonirony))\n",
    "    print(\"{:.2f}%\".format(predB_nonirony/testB_nonirony * 100))\n",
    "    print()\n",
    "\n",
    "    ## 1\n",
    "    print(\"--- 1 Ironic by clash\")\n",
    "    predB_nonirony = sum((used_testB['Label'] == 1) & (y_pred == 1))\n",
    "    testB_nonirony = sum((used_testB['Label'] == 1))\n",
    "    print(str(predB_nonirony) + \"/\" + str(testB_nonirony))\n",
    "    print(\"{:.2f}%\".format(predB_nonirony/testB_nonirony * 100))\n",
    "    print()\n",
    "\n",
    "    ## 2\n",
    "    print(\"--- 2 Situational irony\")\n",
    "    predB_nonirony = sum((used_testB['Label'] == 2) & (y_pred == 1))\n",
    "    testB_nonirony = sum((used_testB['Label'] == 2))\n",
    "    print(str(predB_nonirony) + \"/\" + str(testB_nonirony))\n",
    "    print(\"{:.2f}%\".format(predB_nonirony/testB_nonirony * 100))\n",
    "    print()\n",
    "\n",
    "    ## 3\n",
    "    print(\"--- 3 Other irony\")\n",
    "    predB_nonirony = sum((used_testB['Label'] == 3) & (y_pred == 1))\n",
    "    testB_nonirony = sum((used_testB['Label'] == 3))\n",
    "    print(str(predB_nonirony) + \"/\" + str(testB_nonirony))\n",
    "    print(\"{:.2f}%\".format(predB_nonirony/testB_nonirony * 100))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
