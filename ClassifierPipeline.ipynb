{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import twokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from FeatureFunctions import getfeatures\n",
    "from FeatureFunctions import helper\n",
    "\n",
    "import sklearn\n",
    "import csv\n",
    "\n",
    "\n",
    "### Import the classifier\n",
    "import sys\n",
    "sys.path.insert(0, 'libsvm')\n",
    "\n",
    "from svmutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whichtask = input(\"Which task to you want to do (A/B): \")\n",
    "whichtask = \"A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading train and test files\n",
    "\n",
    "datafile = \"datasets/train/SemEval2018-T3-train-task\"+whichtask+\"_emoji.txt\"\n",
    "# datafile2 = \"datasets/train/SemEval2018-T3-train-taskA_emoji_ironyHashtags.txt\"\n",
    "trainingdata = pd.read_csv(datafile, delimiter = \"\\t\",  quoting=csv.QUOTE_NONE, header=0)\n",
    "trainingdata = trainingdata[['Label','Tweet text']]\n",
    "\n",
    "testfile = 'datasets/goldtest_Task'+whichtask+'/SemEval2018-T3_gold_test_task'+whichtask+'_emoji.txt'\n",
    "\n",
    "testdata = pd.read_csv(testfile, sep=\"\\t\",  quoting=csv.QUOTE_NONE, header=0)\n",
    "testdata = testdata[['Label','Tweet text']]\n",
    "\n",
    "testfileB = 'datasets/goldtest_TaskB/SemEval2018-T3_gold_test_taskB_emoji.txt'\n",
    "testdataB = pd.read_csv(testfileB, sep=\"\\t\",  quoting=csv.QUOTE_NONE, header=0)\n",
    "testdataB = testdataB[['Label','Tweet text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get lexical features\n",
    "# training_features\n",
    "lexical_training_features, unicount_vect, bicount_vect, tricount_vect, fourcount_vect = getfeatures.getlexical(trainingdata, 'Tweet text')\n",
    "x_small = lexical_training_features[['PunctuationFlood', 'CharFlood', 'CapitalizedCount', 'HashtagCount', 'Hashtag2WordRatio', 'TweetCharLength', 'TweetWordLength', 'EmojiCount', 'FinalPunctuation']].values\n",
    "x_lexical = np.array(lexical_training_features.apply(lambda row: sum([row['CharFourgramVector'], row['CharTrigramVector'],row['BigramVector']], []), axis=1).values.tolist())\n",
    "x_lexical = np.hstack((x_small, x_lexical))\n",
    "\n",
    "# train_bow = lexical_training_features['UnigramVector'].values.tolist()\n",
    "\n",
    "# test_features\n",
    "lexical_test_features, unicount_vect, bicount_vect, tricount_vect, fourcount_vect = getfeatures.getlexical(testdata, 'Tweet text', unicount_vect, bicount_vect, tricount_vect, fourcount_vect)\n",
    "test_x_small = lexical_test_features[['PunctuationFlood', 'CharFlood', 'CapitalizedCount', 'HashtagCount', 'Hashtag2WordRatio', 'TweetCharLength', 'TweetWordLength', 'EmojiCount', 'FinalPunctuation']].values\n",
    "test_lexical_x = np.array(lexical_test_features.apply(lambda row: sum([row['CharFourgramVector'], row['CharTrigramVector'],row['BigramVector']], []), axis=1).values.tolist())\n",
    "test_lexical_x = np.hstack((test_x_small, test_lexical_x))\n",
    "\n",
    "train_bow = np.array(lexical_training_features['UnigramVector'].values.tolist())\n",
    "test_bow = np.array(lexical_test_features['UnigramVector'].values.tolist())\n",
    "\n",
    "lexical_training_features = []\n",
    "lexical_test_features = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload  # Python 3.4+ only.\n",
    "reload(getfeatures)\n",
    "\n",
    "### Get sentiment features\n",
    "train_sentiment_x = getfeatures.getaffinfeats(trainingdata['Tweet text'])\n",
    "test_sentiment_x = getfeatures.getaffinfeats(testdata['Tweet text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getindices(trainingdata, testdata):\n",
    "    ### Creating 50-50% balance\n",
    "    ## Train\n",
    "\n",
    "    ### Count the amount of samples\n",
    "    amount_nonirony_train = sum(trainingdata[\"Label\"] == 0)\n",
    "    amount_irony_train = sum(trainingdata[\"Label\"] > 0)\n",
    "    amount_train_amount = min(amount_nonirony_train, amount_irony_train)\n",
    "\n",
    "    ### Sample indices\n",
    "    train_nonirony_index = trainingdata[trainingdata[\"Label\"] == 0].index.to_series()\n",
    "    train_irony_index = trainingdata[trainingdata[\"Label\"] > 0].index.to_series()\n",
    "\n",
    "    train_nonirony_index_samples = train_nonirony_index.sample(amount_train_amount).tolist()\n",
    "    train_irony_index_samples = train_irony_index.sample(amount_train_amount).tolist()\n",
    "\n",
    "    ## Test\n",
    "    amount_nonirony_test = sum(testdata[\"Label\"] == 0)\n",
    "    amount_irony_test = sum(testdata[\"Label\"] > 0)\n",
    "    amount_test_amount = min(amount_nonirony_test, amount_irony_test)\n",
    "\n",
    "    ### Sample indices\n",
    "    test_nonirony_index = testdata[testdata[\"Label\"] == 0].index.to_series()\n",
    "    test_irony_index = testdata[testdata[\"Label\"] > 0].index.to_series()\n",
    "\n",
    "    test_nonirony_index_samples = test_nonirony_index.sample(amount_test_amount).tolist()\n",
    "    test_irony_index_samples = test_irony_index.sample(amount_test_amount).tolist()\n",
    "    \n",
    "    resulting_train_index = train_nonirony_index_samples +train_irony_index_samples\n",
    "    resulting_test_index = test_nonirony_index_samples +test_irony_index_samples\n",
    "\n",
    "    return resulting_train_index, resulting_test_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many iterations: 10\n",
      "Which type to test: 4\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3822, 6)\n",
      "\n",
      "Accuracy = 58.8435% (2249/3822) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(622, 6)\n",
      "\n",
      "Accuracy = 54.3408% (338/622) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5364    0.6399    0.5836       311\n",
      "           1     0.5538    0.4469    0.4947       311\n",
      "\n",
      "   micro avg     0.5434    0.5434    0.5434       622\n",
      "   macro avg     0.5451    0.5434    0.5391       622\n",
      "weighted avg     0.5451    0.5434    0.5391       622\n",
      "\n",
      "Precision: 0.5537848605577689\n",
      "Recall: 0.44694533762057875\n",
      "F1-score: 0.494661921708185\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          199  112  311\n",
      "1          172  139  311\n",
      "All        371  251  622\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 2/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3822, 6)\n",
      "\n",
      "Accuracy = 58.7912% (2247/3822) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(622, 6)\n",
      "\n",
      "Accuracy = 54.1801% (337/622) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5353    0.6334    0.5803       311\n",
      "           1     0.5512    0.4502    0.4956       311\n",
      "\n",
      "   micro avg     0.5418    0.5418    0.5418       622\n",
      "   macro avg     0.5433    0.5418    0.5379       622\n",
      "weighted avg     0.5433    0.5418    0.5379       622\n",
      "\n",
      "Precision: 0.5511811023622047\n",
      "Recall: 0.45016077170418006\n",
      "F1-score: 0.49557522123893805\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          197  114  311\n",
      "1          171  140  311\n",
      "All        368  254  622\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 3/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3822, 6)\n",
      "\n",
      "Accuracy = 58.7127% (2244/3822) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(622, 6)\n",
      "\n",
      "Accuracy = 53.537% (333/622) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5301    0.6238    0.5731       311\n",
      "           1     0.5430    0.4469    0.4903       311\n",
      "\n",
      "   micro avg     0.5354    0.5354    0.5354       622\n",
      "   macro avg     0.5365    0.5354    0.5317       622\n",
      "weighted avg     0.5365    0.5354    0.5317       622\n",
      "\n",
      "Precision: 0.54296875\n",
      "Recall: 0.44694533762057875\n",
      "F1-score: 0.49029982363315694\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          194  117  311\n",
      "1          172  139  311\n",
      "All        366  256  622\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 4/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3822, 6)\n",
      "\n",
      "Accuracy = 58.7389% (2245/3822) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(622, 6)\n",
      "\n",
      "Accuracy = 55.9486% (348/622) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5488    0.6688    0.6029       311\n",
      "           1     0.5761    0.4502    0.5054       311\n",
      "\n",
      "   micro avg     0.5595    0.5595    0.5595       622\n",
      "   macro avg     0.5625    0.5595    0.5542       622\n",
      "weighted avg     0.5625    0.5595    0.5542       622\n",
      "\n",
      "Precision: 0.5761316872427984\n",
      "Recall: 0.45016077170418006\n",
      "F1-score: 0.5054151624548737\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          208  103  311\n",
      "1          171  140  311\n",
      "All        379  243  622\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 5/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3822, 6)\n",
      "\n",
      "Accuracy = 58.6604% (2242/3822) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(622, 6)\n",
      "\n",
      "Accuracy = 54.5016% (339/622) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5376    0.6431    0.5857       311\n",
      "           1     0.5560    0.4469    0.4955       311\n",
      "\n",
      "   micro avg     0.5450    0.5450    0.5450       622\n",
      "   macro avg     0.5468    0.5450    0.5406       622\n",
      "weighted avg     0.5468    0.5450    0.5406       622\n",
      "\n",
      "Precision: 0.556\n",
      "Recall: 0.44694533762057875\n",
      "F1-score: 0.49554367201426025\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          200  111  311\n",
      "1          172  139  311\n",
      "All        372  250  622\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 6/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3822, 6)\n",
      "\n",
      "Accuracy = 58.7389% (2245/3822) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(622, 6)\n",
      "\n",
      "Accuracy = 54.3408% (338/622) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5362    0.6431    0.5848       311\n",
      "           1     0.5542    0.4437    0.4929       311\n",
      "\n",
      "   micro avg     0.5434    0.5434    0.5434       622\n",
      "   macro avg     0.5452    0.5434    0.5388       622\n",
      "weighted avg     0.5452    0.5434    0.5388       622\n",
      "\n",
      "Precision: 0.5542168674698795\n",
      "Recall: 0.4437299035369775\n",
      "F1-score: 0.4928571428571428\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          200  111  311\n",
      "1          173  138  311\n",
      "All        373  249  622\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 7/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3822, 6)\n",
      "\n",
      "Accuracy = 58.7127% (2244/3822) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(622, 6)\n",
      "\n",
      "Accuracy = 53.0547% (330/622) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5263    0.6109    0.5655       311\n",
      "           1     0.5364    0.4502    0.4895       311\n",
      "\n",
      "   micro avg     0.5305    0.5305    0.5305       622\n",
      "   macro avg     0.5314    0.5305    0.5275       622\n",
      "weighted avg     0.5314    0.5305    0.5275       622\n",
      "\n",
      "Precision: 0.5363984674329502\n",
      "Recall: 0.45016077170418006\n",
      "F1-score: 0.4895104895104895\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          190  121  311\n",
      "1          171  140  311\n",
      "All        361  261  622\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 8/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3822, 6)\n",
      "\n",
      "Accuracy = 58.7389% (2245/3822) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(622, 6)\n",
      "\n",
      "Accuracy = 53.2154% (331/622) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5273    0.6206    0.5702       311\n",
      "           1     0.5391    0.4437    0.4868       311\n",
      "\n",
      "   micro avg     0.5322    0.5322    0.5322       622\n",
      "   macro avg     0.5332    0.5322    0.5285       622\n",
      "weighted avg     0.5332    0.5322    0.5285       622\n",
      "\n",
      "Precision: 0.5390625\n",
      "Recall: 0.4437299035369775\n",
      "F1-score: 0.4867724867724868\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          193  118  311\n",
      "1          173  138  311\n",
      "All        366  256  622\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 9/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3822, 6)\n",
      "\n",
      "Accuracy = 58.7912% (2247/3822) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(622, 6)\n",
      "\n",
      "Accuracy = 53.8585% (335/622) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5324    0.6334    0.5786       311\n",
      "           1     0.5476    0.4437    0.4902       311\n",
      "\n",
      "   micro avg     0.5386    0.5386    0.5386       622\n",
      "   macro avg     0.5400    0.5386    0.5344       622\n",
      "weighted avg     0.5400    0.5386    0.5344       622\n",
      "\n",
      "Precision: 0.5476190476190477\n",
      "Recall: 0.4437299035369775\n",
      "F1-score: 0.4902309058614565\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          197  114  311\n",
      "1          173  138  311\n",
      "All        370  252  622\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 10/10\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3822, 6)\n",
      "\n",
      "Accuracy = 58.7389% (2245/3822) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(622, 6)\n",
      "\n",
      "Accuracy = 53.3762% (332/622) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5288    0.6206    0.5710       311\n",
      "           1     0.5409    0.4469    0.4894       311\n",
      "\n",
      "   micro avg     0.5338    0.5338    0.5338       622\n",
      "   macro avg     0.5348    0.5338    0.5302       622\n",
      "weighted avg     0.5348    0.5338    0.5302       622\n",
      "\n",
      "Precision: 0.5408560311284046\n",
      "Recall: 0.44694533762057875\n",
      "F1-score: 0.4894366197183098\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          193  118  311\n",
      "1          172  139  311\n",
      "All        365  257  622\n"
     ]
    }
   ],
   "source": [
    "### Combining features\n",
    "iterations = int(input(\"How many iterations: \"))\n",
    "whichtype = int(input(\"Which type to test: \"))\n",
    "results = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    print()\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(\"Iteration \" + str(i+1) + \"/\" + str(iterations))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print()\n",
    "    \n",
    "    ### Selecting the actual training samples (Do some crossover here )\n",
    "    resulting_train_index, resulting_test_index = getindices(trainingdata, testdata)\n",
    "    trainingdata_result = trainingdata.loc[resulting_train_index]\n",
    "    testdata_result = testdata.loc[resulting_test_index]\n",
    "    \n",
    "    final_train_x = []\n",
    "    final_test_x = []\n",
    "\n",
    "    ## BoW\n",
    "    if whichtype == 1:\n",
    "        final_train_x = train_bow[resulting_train_index]\n",
    "        final_test_x = test_bow[resulting_test_index]\n",
    "    ## Lexical\n",
    "    if whichtype == 2:\n",
    "        final_train_x = np.hstack((train_bow[resulting_train_index], x_lexical[resulting_train_index]))\n",
    "        final_test_x = np.hstack((test_bow[resulting_test_index], test_lexical_x[resulting_test_index]))\n",
    "    ## Sentiment\n",
    "    if whichtype == 4:\n",
    "        final_train_x = train_sentiment_x[resulting_train_index]\n",
    "        final_test_x = test_sentiment_x[resulting_test_index]\n",
    "    ## Combined\n",
    "    if whichtype == 6:\n",
    "        final_train_x = np.hstack((train_bow[resulting_train_index], train_sentiment_x[resulting_train_index], x_lexical[resulting_train_index]))\n",
    "        final_test_x = np.hstack((test_bow[resulting_test_index], test_sentiment_x[resulting_test_index], test_lexical_x[resulting_test_index]))\n",
    "\n",
    "\n",
    "    print(\"###########\")\n",
    "    print(\"Training:\")\n",
    "    print(final_train_x.shape)\n",
    "    print()\n",
    "    ### Train and get train error\n",
    "    y = trainingdata_result['Label'].tolist()\n",
    "    prob  = svm_problem(y, final_train_x)\n",
    "    param = svm_parameter('-t 2 -c 8 -g ' + str(2**-11))\n",
    "    m = svm_train(prob, param)\n",
    "    p_label, p_acc, p_val = svm_predict(y, final_train_x, m)\n",
    "    ACC, MSE, SCC = evaluations(y, p_label)\n",
    "\n",
    "    print()\n",
    "    print(\"###########\")\n",
    "    print(\"Testing:\")\n",
    "    print(final_test_x.shape)\n",
    "    print()\n",
    "\n",
    "\n",
    "    ### Get the test\n",
    "    test_y = testdata_result['Label'].tolist()\n",
    "\n",
    "    test_p_label, test_p_acc, test_p_val = svm_predict(test_y, final_test_x, m)\n",
    "    test_ACC, test_MSE, test_SCC = evaluations(test_y, test_p_label)\n",
    "    print(sklearn.metrics.classification_report(test_y, test_p_label, digits=4))\n",
    "\n",
    "    if whichtask == \"A\":\n",
    "        p, r, f = helper.precision_recall_fscore(test_y, test_p_label, beta=1, labels=[0,1], pos_label=1)\n",
    "    elif whichtask == \"B\":\n",
    "        p, r, f = helper.precision_recall_fscore(test_y, test_p_label, beta=1, labels=[0,1,2,3])\n",
    "\n",
    "    print(\"Precision: \" + str(p))\n",
    "    print(\"Recall: \" + str(r))\n",
    "    print(\"F1-score: \" + str(f))\n",
    "    \n",
    "    results.append([test_ACC, p*100, r*100, f*100])\n",
    "\n",
    "    y_actu = pd.Series(test_y, name='Actual')\n",
    "    y_pred = pd.Series(test_p_label, name='Predicted')\n",
    "    df_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print(df_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic results:\n",
      "54.04±1.60\t54.98±2.19\t44.69±0.50\t49.30±1.00\t\n"
     ]
    }
   ],
   "source": [
    "mean_results = np.mean(np.array(results), axis=0)\n",
    "std_results = 2*np.std(np.array(results), axis=0)\n",
    "\n",
    "if whichtype == 1:\n",
    "    print(\"BoW results:\")\n",
    "elif whichtype == 2:\n",
    "    print(\"Lexical results:\")\n",
    "elif whichtype == 4:\n",
    "    print(\"Semantic results:\")\n",
    "elif whichtype == 6:\n",
    "    print(\"Combined results:\")\n",
    "        \n",
    "\n",
    "for result_i in range(len(mean_results)):\n",
    "    sys.stdout.write(\"{:.2f}\".format(mean_results[result_i]) + \"±\" + \"{:.2f}\".format(std_results[result_i]) + \"\\t\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Non-ironic\n",
      "145/311\n",
      "46.62%\n",
      "\n",
      "--- 1\n",
      "52/164\n",
      "31.71%\n",
      "\n",
      "--- 2\n",
      "28/85\n",
      "32.94%\n",
      "\n",
      "--- 3\n",
      "15/62\n",
      "24.19%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Evaluate results per category (Sectie 5.2)\n",
    "\n",
    "## Getting category information\n",
    "used_testB = testdataB.loc[resulting_test_index]\n",
    "\n",
    "## Nonirony\n",
    "print(\"--- Non-ironic\")\n",
    "predB_nonirony = sum((used_testB['Label'] == 0) & (y_pred == 0))\n",
    "testB_nonirony = sum((used_testB['Label'] == 0))\n",
    "print(str(predB_nonirony) + \"/\" + str(testB_nonirony))\n",
    "print(\"{:.2f}%\".format(predB_nonirony/testB_nonirony * 100))\n",
    "print()\n",
    "\n",
    "## 1\n",
    "print(\"--- 1\")\n",
    "predB_nonirony = sum((used_testB['Label'] == 1) & (y_pred == 1))\n",
    "testB_nonirony = sum((used_testB['Label'] == 1))\n",
    "print(str(predB_nonirony) + \"/\" + str(testB_nonirony))\n",
    "print(\"{:.2f}%\".format(predB_nonirony/testB_nonirony * 100))\n",
    "print()\n",
    "\n",
    "## 2\n",
    "print(\"--- 2\")\n",
    "predB_nonirony = sum((used_testB['Label'] == 2) & (y_pred == 1))\n",
    "testB_nonirony = sum((used_testB['Label'] == 2))\n",
    "print(str(predB_nonirony) + \"/\" + str(testB_nonirony))\n",
    "print(\"{:.2f}%\".format(predB_nonirony/testB_nonirony * 100))\n",
    "print()\n",
    "\n",
    "## 3\n",
    "print(\"--- 3\")\n",
    "predB_nonirony = sum((used_testB['Label'] == 3) & (y_pred == 1))\n",
    "testB_nonirony = sum((used_testB['Label'] == 3))\n",
    "print(str(predB_nonirony) + \"/\" + str(testB_nonirony))\n",
    "print(\"{:.2f}%\".format(predB_nonirony/testB_nonirony * 100))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
