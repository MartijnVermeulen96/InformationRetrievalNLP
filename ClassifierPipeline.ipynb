{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import twokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from FeatureFunctions import getfeatures\n",
    "from FeatureFunctions import helper\n",
    "from sklearn.externals import joblib\n",
    "from gensim.models import Word2Vec\n",
    "from importlib import reload\n",
    "\n",
    "import sklearn\n",
    "import csv\n",
    "\n",
    "\n",
    "### Import the classifier\n",
    "import sys\n",
    "sys.path.insert(0, 'libsvm')\n",
    "\n",
    "from svmutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whichtask = input(\"Which task to you want to do (A/B): \")\n",
    "whichtask = \"A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading train and test files\n",
    "\n",
    "datafile = \"datasets/train/SemEval2018-T3-train-task\"+whichtask+\"_emoji.txt\"\n",
    "trainingdata = pd.read_csv(datafile, delimiter = \"\\t\",  quoting=csv.QUOTE_NONE, header=0)\n",
    "trainingdata = trainingdata[['Label','Tweet text']]\n",
    "\n",
    "testfile = 'datasets/goldtest_Task'+whichtask+'/SemEval2018-T3_gold_test_task'+whichtask+'_emoji.txt'\n",
    "testdata = pd.read_csv(testfile, sep=\"\\t\",  quoting=csv.QUOTE_NONE, header=0)\n",
    "testdata = testdata[['Label','Tweet text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'FeatureFunctions.helper' from '/root/Documents/TU_Delft/InformationRetrieval/NLP/InformationRetrievalNLP/FeatureFunctions/helper.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_posfeatures = helper.getPOSfeatures(\"FeatureFunctions/POStrain.txt\")\n",
    "test_posfeatures = helper.getPOSfeatures(\"FeatureFunctions/POStest.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get lexical features\n",
    "# training_features\n",
    "lexical_training_features, unicount_vect, bicount_vect, tricount_vect, fourcount_vect = getfeatures.getlexical(trainingdata, 'Tweet text')\n",
    "x_small = lexical_training_features[['PunctuationFlood', 'CharFlood', 'CapitalizedCount', 'HashtagCount', 'Hashtag2WordRatio', 'TweetCharLength', 'TweetWordLength', 'EmojiCount', 'FinalPunctuation']].values\n",
    "x_lexical = np.array(lexical_training_features.apply(lambda row: sum([row['CharFourgramVector'], row['CharTrigramVector'],row['BigramVector']], []), axis=1).values.tolist())\n",
    "x_lexical = np.hstack((x_small, x_lexical))\n",
    "\n",
    "# train_bow = lexical_training_features['UnigramVector'].values.tolist()\n",
    "\n",
    "# test_features\n",
    "lexical_test_features, unicount_vect, bicount_vect, tricount_vect, fourcount_vect = getfeatures.getlexical(testdata, 'Tweet text', unicount_vect, bicount_vect, tricount_vect, fourcount_vect)\n",
    "test_x_small = lexical_test_features[['PunctuationFlood', 'CharFlood', 'CapitalizedCount', 'HashtagCount', 'Hashtag2WordRatio', 'TweetCharLength', 'TweetWordLength', 'EmojiCount', 'FinalPunctuation']].values\n",
    "test_lexical_x = np.array(lexical_test_features.apply(lambda row: sum([row['CharFourgramVector'], row['CharTrigramVector'],row['BigramVector']], []), axis=1).values.tolist())\n",
    "test_lexical_x = np.hstack((test_x_small, test_lexical_x))\n",
    "\n",
    "train_bow = np.array(lexical_training_features['UnigramVector'].values.tolist())\n",
    "test_bow = np.array(lexical_test_features['UnigramVector'].values.tolist())\n",
    "\n",
    "lexical_training_features = []\n",
    "lexical_test_features = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the classifier\n",
    "kmeansmodel = joblib.load(\"FeatureFunctions/kmeansclass.model\")\n",
    "w2vmodel = Word2Vec.load(\"FeatureFunctions/word2vec.model\")\n",
    "\n",
    "train_bags = helper.allbags(trainingdata['Tweet text'])\n",
    "word2vecfeatures_train = helper.onehotwordclusters(train_bags, kmeansmodel, w2vmodel).astype(int)\n",
    "\n",
    "test_bags = helper.allbags(testdata['Tweet text'])\n",
    "word2vecfeatures_test = helper.onehotwordclusters(test_bags, kmeansmodel, w2vmodel).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(getfeatures)\n",
    "\n",
    "### Get sentiment features\n",
    "train_sentiment_x = getfeatures.getaffinfeats(trainingdata['Tweet text'])\n",
    "test_sentiment_x = getfeatures.getaffinfeats(testdata['Tweet text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many iterations: 50\n",
      "Do you want to use a heldout set (1=heldout, 0=crossvalidate): 0\n",
      "Which type to test: 2\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1/50\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 94070)\n",
      "\n",
      "Accuracy = 92.9693% (2843/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 94070)\n",
      "\n",
      "Accuracy = 71.2598% (543/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7396    0.6562    0.6954       381\n",
      "           1     0.6910    0.7690    0.7280       381\n",
      "\n",
      "   micro avg     0.7126    0.7126    0.7126       762\n",
      "   macro avg     0.7153    0.7126    0.7117       762\n",
      "weighted avg     0.7153    0.7126    0.7117       762\n",
      "\n",
      "Precision: 0.6910377358490566\n",
      "Recall: 0.7690288713910761\n",
      "F1-score: 0.7279503105590063\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          250  131  381\n",
      "1           88  293  381\n",
      "All        338  424  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 2/50\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 94070)\n",
      "\n",
      "Accuracy = 92.3479% (2824/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 94070)\n",
      "\n",
      "Accuracy = 70.0787% (534/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7284    0.6404    0.6816       381\n",
      "           1     0.6792    0.7612    0.7178       381\n",
      "\n",
      "   micro avg     0.7008    0.7008    0.7008       762\n",
      "   macro avg     0.7038    0.7008    0.6997       762\n",
      "weighted avg     0.7038    0.7008    0.6997       762\n",
      "\n",
      "Precision: 0.6791569086651054\n",
      "Recall: 0.7611548556430446\n",
      "F1-score: 0.7178217821782178\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          244  137  381\n",
      "1           91  290  381\n",
      "All        335  427  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 3/50\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 94070)\n",
      "\n",
      "Accuracy = 92.5441% (2830/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 94070)\n",
      "\n",
      "Accuracy = 67.3228% (513/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7000    0.6063    0.6498       381\n",
      "           1     0.6528    0.7402    0.6937       381\n",
      "\n",
      "   micro avg     0.6732    0.6732    0.6732       762\n",
      "   macro avg     0.6764    0.6732    0.6718       762\n",
      "weighted avg     0.6764    0.6732    0.6718       762\n",
      "\n",
      "Precision: 0.6527777777777778\n",
      "Recall: 0.7401574803149606\n",
      "F1-score: 0.6937269372693727\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          231  150  381\n",
      "1           99  282  381\n",
      "All        330  432  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 4/50\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 94070)\n",
      "\n",
      "Accuracy = 92.3152% (2823/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 94070)\n",
      "\n",
      "Accuracy = 70.0787% (534/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7243    0.6483    0.6842       381\n",
      "           1     0.6817    0.7533    0.7157       381\n",
      "\n",
      "   micro avg     0.7008    0.7008    0.7008       762\n",
      "   macro avg     0.7030    0.7008    0.7000       762\n",
      "weighted avg     0.7030    0.7008    0.7000       762\n",
      "\n",
      "Precision: 0.6817102137767221\n",
      "Recall: 0.7532808398950132\n",
      "F1-score: 0.7157107231920201\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          247  134  381\n",
      "1           94  287  381\n",
      "All        341  421  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 5/50\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 94070)\n",
      "\n",
      "Accuracy = 92.8712% (2840/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 94070)\n",
      "\n",
      "Accuracy = 68.2415% (520/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7050    0.6273    0.6639       381\n",
      "           1     0.6643    0.7375    0.6990       381\n",
      "\n",
      "   micro avg     0.6824    0.6824    0.6824       762\n",
      "   macro avg     0.6847    0.6824    0.6814       762\n",
      "weighted avg     0.6847    0.6824    0.6814       762\n",
      "\n",
      "Precision: 0.6643026004728132\n",
      "Recall: 0.7375328083989501\n",
      "F1-score: 0.6990049751243781\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          239  142  381\n",
      "1          100  281  381\n",
      "All        339  423  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 6/50\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 94070)\n",
      "\n",
      "Accuracy = 92.9693% (2843/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 94070)\n",
      "\n",
      "Accuracy = 71.2598% (543/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7411    0.6535    0.6946       381\n",
      "           1     0.6901    0.7717    0.7286       381\n",
      "\n",
      "   micro avg     0.7126    0.7126    0.7126       762\n",
      "   macro avg     0.7156    0.7126    0.7116       762\n",
      "weighted avg     0.7156    0.7126    0.7116       762\n",
      "\n",
      "Precision: 0.6901408450704225\n",
      "Recall: 0.7716535433070866\n",
      "F1-score: 0.728624535315985\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          249  132  381\n",
      "1           87  294  381\n",
      "All        336  426  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 7/50\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 94070)\n",
      "\n",
      "Accuracy = 92.4133% (2826/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 94070)\n",
      "\n",
      "Accuracy = 70.3412% (536/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7399    0.6273    0.6790       381\n",
      "           1     0.6765    0.7795    0.7244       381\n",
      "\n",
      "   micro avg     0.7034    0.7034    0.7034       762\n",
      "   macro avg     0.7082    0.7034    0.7017       762\n",
      "weighted avg     0.7082    0.7034    0.7017       762\n",
      "\n",
      "Precision: 0.6765375854214123\n",
      "Recall: 0.7795275590551181\n",
      "F1-score: 0.724390243902439\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          239  142  381\n",
      "1           84  297  381\n",
      "All        323  439  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 8/50\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 94070)\n",
      "\n",
      "Accuracy = 93.1655% (2849/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 94070)\n",
      "\n",
      "Accuracy = 68.8976% (525/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7118    0.6352    0.6713       381\n",
      "           1     0.6706    0.7428    0.7049       381\n",
      "\n",
      "   micro avg     0.6890    0.6890    0.6890       762\n",
      "   macro avg     0.6912    0.6890    0.6881       762\n",
      "weighted avg     0.6912    0.6890    0.6881       762\n",
      "\n",
      "Precision: 0.6706161137440758\n",
      "Recall: 0.7427821522309711\n",
      "F1-score: 0.7048567870485679\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          242  139  381\n",
      "1           98  283  381\n",
      "All        340  422  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 9/50\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 94070)\n",
      "\n",
      "Accuracy = 92.3479% (2824/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 94070)\n",
      "\n",
      "Accuracy = 68.2415% (520/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7309    0.5774    0.6452       381\n",
      "           1     0.6508    0.7874    0.7126       381\n",
      "\n",
      "   micro avg     0.6824    0.6824    0.6824       762\n",
      "   macro avg     0.6908    0.6824    0.6789       762\n",
      "weighted avg     0.6908    0.6824    0.6789       762\n",
      "\n",
      "Precision: 0.6507592190889371\n",
      "Recall: 0.7874015748031497\n",
      "F1-score: 0.7125890736342043\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          220  161  381\n",
      "1           81  300  381\n",
      "All        301  461  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 10/50\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 94070)\n",
      "\n",
      "Accuracy = 91.7593% (2806/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 94070)\n",
      "\n",
      "Accuracy = 67.3228% (513/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6813    0.6509    0.6658       381\n",
      "           1     0.6658    0.6955    0.6804       381\n",
      "\n",
      "   micro avg     0.6732    0.6732    0.6732       762\n",
      "   macro avg     0.6736    0.6732    0.6731       762\n",
      "weighted avg     0.6736    0.6732    0.6731       762\n",
      "\n",
      "Precision: 0.6658291457286433\n",
      "Recall: 0.6955380577427821\n",
      "F1-score: 0.6803594351732991\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          248  133  381\n",
      "1          116  265  381\n",
      "All        364  398  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 11/50\n",
      "-------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########\n",
      "Training:\n",
      "(3058, 94070)\n",
      "\n",
      "Accuracy = 92.9039% (2841/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 94070)\n",
      "\n",
      "Accuracy = 69.2913% (528/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7234    0.6247    0.6704       381\n",
      "           1     0.6697    0.7612    0.7125       381\n",
      "\n",
      "   micro avg     0.6929    0.6929    0.6929       762\n",
      "   macro avg     0.6966    0.6929    0.6915       762\n",
      "weighted avg     0.6966    0.6929    0.6915       762\n",
      "\n",
      "Precision: 0.6697459584295612\n",
      "Recall: 0.7611548556430446\n",
      "F1-score: 0.7125307125307124\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          238  143  381\n",
      "1           91  290  381\n",
      "All        329  433  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 12/50\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 94070)\n",
      "\n",
      "Accuracy = 92.2498% (2821/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 94070)\n",
      "\n",
      "Accuracy = 66.9291% (510/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7035    0.5853    0.6390       381\n",
      "           1     0.6449    0.7533    0.6949       381\n",
      "\n",
      "   micro avg     0.6693    0.6693    0.6693       762\n",
      "   macro avg     0.6742    0.6693    0.6669       762\n",
      "weighted avg     0.6742    0.6693    0.6669       762\n",
      "\n",
      "Precision: 0.6449438202247191\n",
      "Recall: 0.7532808398950132\n",
      "F1-score: 0.6949152542372882\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          223  158  381\n",
      "1           94  287  381\n",
      "All        317  445  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 13/50\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 94070)\n",
      "\n",
      "Accuracy = 92.7077% (2835/3058) (classification)\n",
      "\n",
      "###########\n",
      "Testing:\n",
      "(762, 94070)\n",
      "\n",
      "Accuracy = 72.4409% (552/762) (classification)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7697    0.6404    0.6991       381\n",
      "           1     0.6921    0.8084    0.7458       381\n",
      "\n",
      "   micro avg     0.7244    0.7244    0.7244       762\n",
      "   macro avg     0.7309    0.7244    0.7225       762\n",
      "weighted avg     0.7309    0.7244    0.7225       762\n",
      "\n",
      "Precision: 0.6921348314606741\n",
      "Recall: 0.8083989501312336\n",
      "F1-score: 0.7457627118644068\n",
      "\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0          244  137  381\n",
      "1           73  308  381\n",
      "All        317  445  762\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Iteration 14/50\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "###########\n",
      "Training:\n",
      "(3058, 94070)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Combining features\n",
    "iterations = int(input(\"How many iterations: \"))\n",
    "# nuSVC = int(input(\"Use nusvc? (1):\"))\n",
    "nuSVC = 0\n",
    "heldoutset = int(input(\"Do you want to use a heldout set (1=heldout, 0=crossvalidate): \"))\n",
    "whichtype = int(input(\"Which type to test: \"))\n",
    "results = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    print()\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(\"Iteration \" + str(i+1) + \"/\" + str(iterations))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print()\n",
    "    \n",
    "    ### Selecting the actual training samples (Do some crossover here )\n",
    "    if heldoutset:\n",
    "        trainingdata_result = trainingdata\n",
    "        testdata_result = testdata\n",
    "        resulting_train_index = range(len(trainingdata))\n",
    "        resulting_test_index = range(len(testdata_result))\n",
    "    else:\n",
    "        ## Crossvalidating\n",
    "        resulting_train_index, resulting_test_index = helper.getindices(trainingdata, 4, 1) # Get 80-20\n",
    "        trainingdata_result = trainingdata.loc[resulting_train_index]\n",
    "        testdata_result = trainingdata.loc[resulting_test_index]\n",
    "    \n",
    "    final_train_x = []\n",
    "    final_test_x = []\n",
    "\n",
    "    if heldoutset:\n",
    "        ## BoW\n",
    "        if whichtype == 1:\n",
    "            final_train_x = train_bow[resulting_train_index]\n",
    "            final_test_x = test_bow[resulting_test_index]\n",
    "        ## Lexical\n",
    "        if whichtype == 2:\n",
    "            final_train_x = np.hstack((train_bow[resulting_train_index], x_lexical[resulting_train_index]))\n",
    "            final_test_x = np.hstack((test_bow[resulting_test_index], test_lexical_x[resulting_test_index]))\n",
    "        ## Syntactic\n",
    "        if whichtype == 3:\n",
    "            final_train_x = train_posfeatures[resulting_train_index]\n",
    "            final_test_x = test_posfeatures[resulting_test_index]\n",
    "        ## Sentiment\n",
    "        if whichtype == 4:\n",
    "            final_train_x = train_sentiment_x[resulting_train_index]\n",
    "            final_test_x = test_sentiment_x[resulting_test_index]\n",
    "        ## Word2Vec\n",
    "        if whichtype == 5:\n",
    "            final_train_x = word2vecfeatures_train[resulting_train_index]\n",
    "            final_test_x = word2vecfeatures_test[resulting_test_index]\n",
    "        ## Combined\n",
    "        if whichtype == 6:\n",
    "            final_train_x = np.hstack((train_posfeatures[resulting_train_index], word2vecfeatures_train[resulting_train_index],train_bow[resulting_train_index], train_sentiment_x[resulting_train_index], x_lexical[resulting_train_index]))\n",
    "            final_test_x = np.hstack((test_posfeatures[resulting_test_index], word2vecfeatures_test[resulting_test_index], test_bow[resulting_test_index], test_sentiment_x[resulting_test_index], test_lexical_x[resulting_test_index]))\n",
    "    else:\n",
    "        ## Crossvalidating\n",
    "        ## BoW\n",
    "        if whichtype == 1:\n",
    "            final_train_x = train_bow[resulting_train_index]\n",
    "            final_test_x = train_bow[resulting_test_index]\n",
    "        ## Lexical\n",
    "        if whichtype == 2:\n",
    "            final_train_x = np.hstack((train_bow[resulting_train_index], x_lexical[resulting_train_index]))\n",
    "            final_test_x = np.hstack((train_bow[resulting_test_index], x_lexical[resulting_test_index]))\n",
    "        ## Syntactic\n",
    "        if whichtype == 3:\n",
    "            final_train_x = train_posfeatures[resulting_train_index]\n",
    "            final_test_x = train_posfeatures[resulting_test_index]\n",
    "        ## Sentiment\n",
    "        if whichtype == 4:\n",
    "            final_train_x = train_sentiment_x[resulting_train_index]\n",
    "            final_test_x = train_sentiment_x[resulting_test_index]\n",
    "        ## Word2Vec\n",
    "        if whichtype == 5:\n",
    "            final_train_x = word2vecfeatures_train[resulting_train_index]\n",
    "            final_test_x = word2vecfeatures_train[resulting_test_index]\n",
    "        ## Combined\n",
    "        if whichtype == 6:\n",
    "            final_train_x = np.hstack((train_posfeatures[resulting_train_index], word2vecfeatures_train[resulting_train_index], train_bow[resulting_train_index], train_sentiment_x[resulting_train_index], x_lexical[resulting_train_index]))\n",
    "            final_test_x = np.hstack((train_posfeatures[resulting_test_index], word2vecfeatures_train[resulting_test_index], train_bow[resulting_test_index], train_sentiment_x[resulting_test_index], x_lexical[resulting_test_index]))\n",
    "\n",
    "\n",
    "    print(\"###########\")\n",
    "    print(\"Training:\")\n",
    "    print(final_train_x.shape)\n",
    "    print()\n",
    "    ### Train and get train error\n",
    "    y = trainingdata_result['Label'].tolist()\n",
    "    prob  = svm_problem(y, final_train_x)\n",
    "    if nuSVC:\n",
    "        param = svm_parameter('-t 2 -s 1')\n",
    "    else:\n",
    "        param = svm_parameter('-t 2 -c 8 -g ' + str(2**-11))\n",
    "    m = svm_train(prob, param)\n",
    "    p_label, p_acc, p_val = svm_predict(y, final_train_x, m)\n",
    "    ACC, MSE, SCC = evaluations(y, p_label)\n",
    "\n",
    "    print()\n",
    "    print(\"###########\")\n",
    "    print(\"Testing:\")\n",
    "    print(final_test_x.shape)\n",
    "    print()\n",
    "\n",
    "\n",
    "    ### Get the test\n",
    "    test_y = testdata_result['Label'].tolist()\n",
    "\n",
    "    test_p_label, test_p_acc, test_p_val = svm_predict(test_y, final_test_x, m)\n",
    "    test_ACC, test_MSE, test_SCC = evaluations(test_y, test_p_label)\n",
    "    print(sklearn.metrics.classification_report(test_y, test_p_label, digits=4))\n",
    "\n",
    "    if whichtask == \"A\":\n",
    "        p, r, f = helper.precision_recall_fscore(test_y, test_p_label, beta=1, labels=[0,1], pos_label=1)\n",
    "    elif whichtask == \"B\":\n",
    "        p, r, f = helper.precision_recall_fscore(test_y, test_p_label, beta=1, labels=[0,1,2,3])\n",
    "\n",
    "    print(\"Precision: \" + str(p))\n",
    "    print(\"Recall: \" + str(r))\n",
    "    print(\"F1-score: \" + str(f))\n",
    "    \n",
    "    results.append([test_ACC, p*100, r*100, f*100])\n",
    "\n",
    "    y_actu = pd.Series(test_y, name='Actual')\n",
    "    y_pred = pd.Series(test_p_label, name='Predicted')\n",
    "    df_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print(df_confusion)\n",
    "    \n",
    "\n",
    "### Write output\n",
    "mean_results = np.mean(np.array(results), axis=0)\n",
    "std_results = 2*np.std(np.array(results), axis=0)\n",
    "min_results = np.min(np.array(results), axis=0)\n",
    "max_results = np.max(np.array(results), axis=0)\n",
    "\n",
    "if whichtype == 1:\n",
    "    sys.stdout.write(\"BoW results\")\n",
    "elif whichtype == 2:\n",
    "    sys.stdout.write(\"Lexical results\")\n",
    "elif whichtype == 3:\n",
    "    sys.stdout.write(\"Syntactical results\")\n",
    "elif whichtype == 4:\n",
    "    sys.stdout.write(\"Semantic results\")\n",
    "elif whichtype == 5:\n",
    "    sys.stdout.write(\"Word2Vec results\")\n",
    "elif whichtype == 6:\n",
    "    sys.stdout.write(\"Combined results\")\n",
    "    \n",
    "### stdout\n",
    "print(\" with \" + str(iterations) + \" iterations: \")\n",
    "for result_i in range(len(mean_results)):\n",
    "    sys.stdout.write(\"{:.2f}\".format(mean_results[result_i]))\n",
    "    sys.stdout.write(\" ±\" + \"{:.2f}\".format(std_results[result_i]))\n",
    "    sys.stdout.write(\" -\" + \"{:.2f}\".format(min_results[result_i]))\n",
    "    sys.stdout.write(\" +\" + \"{:.2f}\".format(max_results[result_i]) + \"\\t\")\n",
    "    \n",
    "    \n",
    "### file out\n",
    "with open(\"Results/resultswrite.txt\", \"a\") as outfile:\n",
    "    if whichtype == 1:\n",
    "        outfile.write(\"BoW results\")\n",
    "    elif whichtype == 2:\n",
    "        outfile.write(\"Lexical results\")\n",
    "    elif whichtype == 3:\n",
    "        outfile.write(\"Syntactical results\")\n",
    "    elif whichtype == 4:\n",
    "        outfile.write(\"Semantic results\")\n",
    "    elif whichtype == 5:\n",
    "        outfile.write(\"Word2Vec results\")\n",
    "    elif whichtype == 6:\n",
    "        outfile.write(\"Combined results\")\n",
    "\n",
    "    ### stdout\n",
    "    outfile.write(\" with \" + str(iterations) + \" iterations: \\n\")\n",
    "    for result_i in range(len(mean_results)):\n",
    "        outfile.write(\"{:.2f}\".format(mean_results[result_i]))\n",
    "        outfile.write(\" ±\" + \"{:.2f}\".format(std_results[result_i]))\n",
    "        outfile.write(\" -\" + \"{:.2f}\".format(min_results[result_i]))\n",
    "        outfile.write(\" +\" + \"{:.2f}\".format(max_results[result_i]) + \"\\t\")\n",
    "        \n",
    "    outfile.write(\"\\n\\n\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0 Not ironic\n",
      "473/473\n",
      "100.00%\n",
      "\n",
      "--- 1 Ironic by clash\n",
      "0/164\n",
      "0.00%\n",
      "\n",
      "--- 2 Situational irony\n",
      "0/85\n",
      "0.00%\n",
      "\n",
      "--- 3 Other irony\n",
      "0/62\n",
      "0.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if heldoutset:\n",
    "    ### Evaluate results per category (Sectie 5.2)\n",
    "\n",
    "    testfileB = 'datasets/goldtest_TaskB/SemEval2018-T3_gold_test_taskB_emoji.txt'\n",
    "    testdataB = pd.read_csv(testfileB, sep=\"\\t\",  quoting=csv.QUOTE_NONE, header=0)\n",
    "    testdataB = testdataB[['Label','Tweet text']]\n",
    "\n",
    "    ## Getting category information\n",
    "    used_testB = testdataB.loc[resulting_test_index]\n",
    "    used_testB.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    ## Nonirony\n",
    "    print(\"--- 0 Not ironic\")\n",
    "    predB_nonirony = sum((used_testB['Label'] == 0) & (y_pred == 0))\n",
    "    testB_nonirony = sum((used_testB['Label'] == 0))\n",
    "    print(str(predB_nonirony) + \"/\" + str(testB_nonirony))\n",
    "    print(\"{:.2f}%\".format(predB_nonirony/testB_nonirony * 100))\n",
    "    print()\n",
    "\n",
    "    ## 1\n",
    "    print(\"--- 1 Ironic by clash\")\n",
    "    predB_nonirony = sum((used_testB['Label'] == 1) & (y_pred == 1))\n",
    "    testB_nonirony = sum((used_testB['Label'] == 1))\n",
    "    print(str(predB_nonirony) + \"/\" + str(testB_nonirony))\n",
    "    print(\"{:.2f}%\".format(predB_nonirony/testB_nonirony * 100))\n",
    "    print()\n",
    "\n",
    "    ## 2\n",
    "    print(\"--- 2 Situational irony\")\n",
    "    predB_nonirony = sum((used_testB['Label'] == 2) & (y_pred == 1))\n",
    "    testB_nonirony = sum((used_testB['Label'] == 2))\n",
    "    print(str(predB_nonirony) + \"/\" + str(testB_nonirony))\n",
    "    print(\"{:.2f}%\".format(predB_nonirony/testB_nonirony * 100))\n",
    "    print()\n",
    "\n",
    "    ## 3\n",
    "    print(\"--- 3 Other irony\")\n",
    "    predB_nonirony = sum((used_testB['Label'] == 3) & (y_pred == 1))\n",
    "    testB_nonirony = sum((used_testB['Label'] == 3))\n",
    "    print(str(predB_nonirony) + \"/\" + str(testB_nonirony))\n",
    "    print(\"{:.2f}%\".format(predB_nonirony/testB_nonirony * 100))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
