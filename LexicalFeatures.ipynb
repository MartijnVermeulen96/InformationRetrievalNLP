{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import twokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from FeatureFunctions import getfeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"datasets/train/SemEval2018-T3-train-taskA_emoji.txt\"\n",
    "datafile2 = \"datasets/train/SemEval2018-T3-train-taskA_emoji_ironyHashtags.txt\"\n",
    "trainingdata = pd.read_csv(datafile, sep = \"\\t\", header=0)\n",
    "\n",
    "type(trainingdata['Tweet text'])\n",
    "trainingdata = trainingdata[['Label','Tweet text']]\n",
    "train_tweets = trainingdata['Tweet text']\n",
    "\n",
    "testfile = 'datasets/goldtest_TaskA/SemEval2018-T3_gold_test_taskA_emoji.txt'\n",
    "testdata = pd.read_csv(testfile, sep=\"\\t\", header=0)\n",
    "testdata = testdata[['Label','Tweet text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = getfeatures.getlexical(trainingdata, 'Tweet text')\n",
    "test_features = getfeatures.getlexical(testdata, 'Tweet text')\n",
    "# training_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Write to file\n",
    "\n",
    "# outputfolder = input(\"Output folder: \")\n",
    "# outputname = input(\"Output name + extension: \")\n",
    "# trainingdata.to_csv(outputfolder + \"/\" + outputname, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import the classifier\n",
    "import sys\n",
    "sys.path.insert(0, 'libsvm')\n",
    "\n",
    "from svmutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create X and Y\n",
    "## Binary + scalar features\n",
    "# x = training_features[['PunctuationFlood', 'CharFlood', 'CapitalizedCount', 'HashtagCount', 'Hashtag2WordRatio', 'TweetCharLength', 'TweetWordLength', 'EmojiCount', 'FinalPunctuation']].values\n",
    "\n",
    "## Vector features - ToDo\n",
    "x = training_features['CharFourgramVector'].values\n",
    "\n",
    "y = trainingdata['Label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.vstack((training_features['CharFourgramVector'], training_features['CharFourgramVector'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 67.016% (2558/3817) (classification)\n"
     ]
    }
   ],
   "source": [
    "### Train and get train error\n",
    "\n",
    "prob  = svm_problem(y, x)\n",
    "param = svm_parameter('-t 2 -c 8 -g ' + str(2**-11))\n",
    "m = svm_train(prob, param)\n",
    "p_label, p_acc, p_val = svm_predict(y, x, m)\n",
    "ACC, MSE, SCC = evaluations(y, p_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 39.6684% (311/784) (classification)\n"
     ]
    }
   ],
   "source": [
    "### Get the test error\n",
    "\n",
    "## Lexical other values\n",
    "# test_x = test_features[['PunctuationFlood', 'CharFlood', 'CapitalizedCount', 'HashtagCount', 'Hashtag2WordRatio', 'TweetCharLength', 'TweetWordLength', 'EmojiCount', 'FinalPunctuation']].values\n",
    "test_x = test_features['CharFourgramVector'].values\n",
    "test_y = testdata['Label'].tolist()\n",
    "\n",
    "test_p_label, test_p_acc, test_p_val = svm_predict(test_y, test_x, m)\n",
    "test_ACC, test_MSE, test_SCC = evaluations(test_y, test_p_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
